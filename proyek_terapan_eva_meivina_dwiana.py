# -*- coding: utf-8 -*-
"""Proyek Terapan_Eva Meivina Dwiana.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vG106rNABgvur__E_hDOyXgkTCkphavv

# Laporan Proyek Machine Learning - Eva Meivina Dwiana

## Import Libraries

Pada tahap ini, berbagai library yang dibutuhkan untuk analisis data, pra-pemrosesan, pelatihan model, dan evaluasi akan diimpor.
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

"""## Load Dataset
Dataset yang digunakan dalam proyek ini awalnya berasal dari Kaggle, kemudian diunggah ke repositori GitHub agar bisa diakses secara langsung melalui URL.
"""

url = "https://raw.githubusercontent.com/Evameivina/heart_ml/refs/heads/main/heart.csv"
heart_df = pd.read_csv(url)

"""## Data Understanding
Tahap ini bertujuan untuk memahami struktur data, melihat lima baris pertama, informasi umum dataset, statistik deskriptif, dan mendeteksi duplikasi data.
"""

print("5 data teratas:")
print(heart_df.head())

print("Info dataset:")
heart_df.info()

print("Statistik deskriptif:")
print(heart_df.describe())

print("Cek duplikat:")
print(f"Jumlah data duplikat: {heart_df.duplicated().sum()}")

print("Cek missing values:")
print(heart_df.isnull().sum())

print("Distribusi target HeartDisease:")
print(heart_df['HeartDisease'].value_counts(normalize=True))

"""### Pisahkan Fitur dan Target"""

X = heart_df.drop('HeartDisease', axis=1)
y = heart_df['HeartDisease']

"""### Tentukan Fitur Numerik dan Kategorikal"""

num_features = ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak']
cat_features = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']

"""### Data Preparation"""

num_transformer = StandardScaler()

cat_transformer = OneHotEncoder(handle_unknown='ignore')

preprocessor = ColumnTransformer(transformers=[
    ('num', num_transformer, num_features),
    ('cat', cat_transformer, cat_features)
])

"""### Split data train dan test (80:20) dengan stratifikasi target"""

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

"""### Fit transform pada train, transform pada test"""

X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

print("Preprocessing selesai.")
print(f"Bentuk X_train_processed: {X_train_processed.shape}")
print(f"Bentuk X_test_processed: {X_test_processed.shape}")

"""### Model 1: Logistic Regression"""

logreg = LogisticRegression(random_state=42, max_iter=1000)
logreg.fit(X_train_processed, y_train)

"""### Model 2: Random Forest"""

rf = RandomForestClassifier(random_state=42)
rf.fit(X_train_processed, y_train)

"""### Hyperparameter tuning pada Random Forest"""

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
}

grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='f1', n_jobs=-1)
grid_search.fit(X_train_processed, y_train)

best_rf = grid_search.best_estimator_
print(f"Best parameters RF: {grid_search.best_params_}")

"""## Evaluation
Model yang telah dilatih kemudian dievaluasi performanya menggunakan metrik seperti akurasi, confusion matrix, dan classification report.
"""

def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    print(classification_report(y_test, y_pred))
    return acc, prec, rec, f1

print("Logistic Regression Evaluation")
logreg_metrics = evaluate_model(logreg, X_test_processed, y_test)

print("Random Forest Evaluation")
rf_metrics = evaluate_model(rf, X_test_processed, y_test)

print("Tuned Random Forest Evaluation")
tuned_rf_metrics = evaluate_model(best_rf, X_test_processed, y_test)

